<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Set Theory Seminar | NYlogic</title>
<meta name="generator" content="Jekyll v3.9.1" />
<meta property="og:title" content="Set Theory Seminar" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="CUNY Logic Seminars" />
<meta property="og:description" content="CUNY Logic Seminars" />
<link rel="canonical" href="http://localhost:4000/set-theory-seminar/2019/04/05/set-theoretic-independence-and-machine-learning.html" />
<meta property="og:url" content="http://localhost:4000/set-theory-seminar/2019/04/05/set-theoretic-independence-and-machine-learning.html" />
<meta property="og:site_name" content="NYlogic" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-05T00:00:00-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Set Theory Seminar" />
<script type="application/ld+json">
{"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/set-theory-seminar/2019/04/05/set-theoretic-independence-and-machine-learning.html"},"datePublished":"2019-04-05T00:00:00-04:00","url":"http://localhost:4000/set-theory-seminar/2019/04/05/set-theoretic-independence-and-machine-learning.html","description":"CUNY Logic Seminars","headline":"Set Theory Seminar","dateModified":"2019-04-05T00:00:00-04:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/assets/css/style.css?v=">
	<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"> 
</script>
<script type="text/javascript">
function toggle(id)
{
	div=document.getElementById(id);
	style=div.style.display;
	if(style=="block")
	{
		if(div.style.setProperty)
		{
			div.style.setProperty('display','none','');
		}
		else
		{
			div.style.setAttribute('display','none');
		}
	}
	else
	{
		if(div.style.setProperty)
		{
			div.style.setProperty('display','block','');
		}
		else
		{
			div.style.setAttribute('display','block');
		}
	}
}
</script>
  </head>
  <body>
    <section class="page-header2">
	
      <h1 class="project-name">Set Theory Seminar</h1>
	  <a href="/" class="nav">NYLogic</a> &nbsp;&nbsp;<a href="/set-theory-seminar.html" class="nav">Set Theory Seminar</a> &nbsp;&nbsp; <a href="/model-theory-seminar.html" class="nav">Model Theory Seminar</a> &nbsp;&nbsp; <a href="/logic-workshop.html" class="nav">Logic Workshop</a> 
	    &nbsp;&nbsp; <a href="/MOPA.html" class="nav">MOPA</a>&nbsp;&nbsp; <a href="/MAMLS.html" class="nav">MAMLS</a>
      	    
    </section>

    <section class="main-content">
      <p><strong>April  5</strong><br>

Micha&#322; Tomasz Godziszewski,

 University of Warsaw<br>
<strong>Set-Theoretic Independence and Machine Learning</strong><br>
<p> In a recent exciting paper <em>Learnability can be undecidable</em> by S. Ben-David et. al. published in <em>Nature Machine Intelligence</em> the authors argue that certain abstract learnability questions are undecidable by ZFC axioms. The general learning problem considered there is to find a way of choosing a finite set that maximizes a particular expected value (within a certain range of error) with an obstacle that the probability distribution is unknown, or more formally&#58;<br> <em>given a family of functions $&#92;mathcal{F}$ from some fixed domain $X$ to the real numbers and an unknown probability distribution $&#92;mu$ over $X$, find, based on a finite sample generated by $&#92;mu$, a function in $&#92;mathcal{F}$ whose expectation with respect to $&#92;mu$ is (close to) maximal.</em>   </p><p> The authors then provide a translation from this statistical framework to infinite comibnatorics: namely, they prove that existence of certain learning functions corresponding to the problem above (the so-called <em>estimating the maximum</em> learners, or EMX-learners) translates into the existence of the so-called monotone compression schemes, which in turn is equivalent to a statement in cardinal arithmetic that is indeed independent of ZFC. Specifically, let $X$ be an infinite set, $Fin(X)$ be the family of its finite subsets, and let $m > k$ be natural nubers. A <em>monotone compressions scheme</em> for $(X, m, k)$ is a function $f: [X]^k &#92;rightarrow Fin(X)$ such that $$&#92;forall A &#92;in [X]^m &#92;exists B &#92;in [X]^k &#92;: (B &#92;subseteq A  &#92;subseteq f(B)).$$</p> <p> The main result of the paper then is that there exists a monotone compressions scheme for $([0,1], m+1, m)$ for some $m$ if and only if $2^{&#92;aleph_0} < &#92;aleph_&#92;omega$. </p><p> K.P. Hart immediately observed that the main combinatorial content of the results in the paper is related  to Kuratowski's theorem on decompositions of finite powers of sets and that the monotone compression functions on the unit interval cannot, in a certain sense, be constructive or descriptively nice - namely, they cannot be Borel measurable. During the talk I will introduce the subject of the paper in question, and present the set-theoretic aspects of the main results. </p></p>

      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.<br>
		Webmaster: <a href="http://victoriagitman.github.io">Victoria Gitman</a>
		
		</span>
      </footer>
    </section>

    
  </body>
</html>